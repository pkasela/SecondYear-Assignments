{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qmUaS0hQEgx5",
    "outputId": "a4c46e32-2551-4bd5-9081-4cc552f19097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back to tensorflow client, its recommended to install the cloud tpu client directly with pip install cloud-tpu-client .\n",
      "Tesorflow Version: 2.0.0\n",
      "Keras Version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "lr_decay = ReduceLROnPlateau(monitor='val_loss', \n",
    "                             patience=3, verbose=1, \n",
    "                             factor=0.8, min_lr=1e-4)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "print(\"Tesorflow Version:\", tf.__version__)\n",
    "print(\"Keras Version:\",keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caricamento e Pre-analisi dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "HmpgA76qEgx_",
    "outputId": "c74b71de-181c-4e82-8eb2-6cca13841428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 esempi di training\n",
      "10000 esempi di test\n"
     ]
    }
   ],
   "source": [
    "# Dataset predefinito offerto da keras\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape[0], 'esempi di training')\n",
    "print(x_test.shape[0], 'esempi di test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jRkduQhQEgyD",
    "outputId": "e1f89edc-3f30-4a86-a35c-7d3903e365d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(length, height, width, channel): (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Aggiunta dimensione canali\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "print(\"(length, height, width, channel):\",x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "QY4LW42nEgyG",
    "outputId": "7e6c1ec7-1242-4b23-8524-d9cb43cbe361"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#controllo se le classi sono bilanciate\n",
    "sns.countplot(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvRLtNTbEgyJ"
   },
   "outputs": [],
   "source": [
    "# Conversione di tipo\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "\n",
    "# Conversione in forma categorica\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nXOh7FIPEgyM",
    "outputId": "88cd98b6-3e47-4eda-8968-071735b933bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pddcVHkgEgyR"
   },
   "source": [
    "# Creazione e allenamento del modello\n",
    "## Main assignment Problem\n",
    "\n",
    "* Convoluzione bidimensionale con 32 filtri 3$\\times$3\n",
    "* ReLU\n",
    "* Max pooling bidimensionale con filtro 2$\\times$2\n",
    "* Flattening\n",
    "* Fully-connected che mappi a 128 dimensioni\n",
    "* ReLU\n",
    "* Fully-connected che mappi alla dimensione finale del problema\n",
    "\n",
    "Si aggiunge SoftMax al layer finale visto che è un problema di multi-classificazione\n",
    "\n",
    "La loss usata è il categorical crossentropy con ottimizzatore Adadelta con un learning rate di 0.05 che è stato calcolato con trial and error method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNhElAhMEgyS"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Convoluzione con 32 filtri 3x3 + ReLu\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3),\n",
    "                activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "#Max Pooling con filtri 2x2\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "#FC che mappa a 128 dimensioni  + ReLu\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#FC che mappa alla dimensione finale del problema (i.e. num_classes=10) + Softmax\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#loss:categorical_crossentropy, optimizer:Adadelta, metrica da seguire per rendere\n",
    "#più capibile all'umano l'andamento dell'allenamento\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.05),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "L2lkSX8XEgyV",
    "outputId": "9f3c4dc7-bc72-4852-ccc1-417694973d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salviamo nella variabile history tutti le informazioni derivanti dal model.fit, i.e. i loss e accuracy per train e validation,\n",
    "che poi saranno utili per il plot.\n",
    "\n",
    "Mettiamo il numero di epoche a 50 con un lr_decay in cui il learning rate diminuisce nel caso di un aumento di validation loss per più di 3 volte successivamente e early (Early Stopping) con il quale l'allenamento si ferma se non vi è nessun miglioramento nel validation loss per 10 epoche.\n",
    "\n",
    "Il batch size è stato scelto a 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZvYdpefQEgyY",
    "outputId": "c2b9b275-86f2-44f2-9243-6f0043ac31dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 1.0083 - accuracy: 0.7854 - val_loss: 0.4264 - val_accuracy: 0.8876\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3742 - accuracy: 0.8967 - val_loss: 0.3126 - val_accuracy: 0.9163\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.3080 - accuracy: 0.9118 - val_loss: 0.2731 - val_accuracy: 0.9231\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2746 - accuracy: 0.9211 - val_loss: 0.2495 - val_accuracy: 0.9295\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2502 - accuracy: 0.9276 - val_loss: 0.2292 - val_accuracy: 0.9345\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.2305 - accuracy: 0.9335 - val_loss: 0.2143 - val_accuracy: 0.9365\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.2140 - accuracy: 0.9383 - val_loss: 0.1973 - val_accuracy: 0.9426\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.1988 - accuracy: 0.9427 - val_loss: 0.1834 - val_accuracy: 0.9464\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1855 - accuracy: 0.9459 - val_loss: 0.1715 - val_accuracy: 0.9483\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1734 - accuracy: 0.9503 - val_loss: 0.1620 - val_accuracy: 0.9530\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1630 - accuracy: 0.9533 - val_loss: 0.1543 - val_accuracy: 0.9548\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1536 - accuracy: 0.9562 - val_loss: 0.1494 - val_accuracy: 0.9564\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.1451 - accuracy: 0.9583 - val_loss: 0.1380 - val_accuracy: 0.9604\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1374 - accuracy: 0.9606 - val_loss: 0.1354 - val_accuracy: 0.9604\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.1304 - accuracy: 0.9632 - val_loss: 0.1259 - val_accuracy: 0.9634\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.1241 - accuracy: 0.9644 - val_loss: 0.1211 - val_accuracy: 0.9657\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.1180 - accuracy: 0.9661 - val_loss: 0.1175 - val_accuracy: 0.9650\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.1126 - accuracy: 0.9678 - val_loss: 0.1115 - val_accuracy: 0.9675\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.1076 - accuracy: 0.9698 - val_loss: 0.1066 - val_accuracy: 0.9689\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1029 - accuracy: 0.9712 - val_loss: 0.1044 - val_accuracy: 0.9693\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0988 - accuracy: 0.9724 - val_loss: 0.1010 - val_accuracy: 0.9709\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0950 - accuracy: 0.9737 - val_loss: 0.0976 - val_accuracy: 0.9710\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0909 - accuracy: 0.9744 - val_loss: 0.0932 - val_accuracy: 0.9727\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0877 - accuracy: 0.9758 - val_loss: 0.0905 - val_accuracy: 0.9724\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0843 - accuracy: 0.9768 - val_loss: 0.0892 - val_accuracy: 0.9738\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0816 - accuracy: 0.9778 - val_loss: 0.0873 - val_accuracy: 0.9742\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0787 - accuracy: 0.9781 - val_loss: 0.0842 - val_accuracy: 0.9743\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0760 - accuracy: 0.9793 - val_loss: 0.0825 - val_accuracy: 0.9753\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0735 - accuracy: 0.9798 - val_loss: 0.0808 - val_accuracy: 0.9757\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0714 - accuracy: 0.9803 - val_loss: 0.0794 - val_accuracy: 0.9759\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0689 - accuracy: 0.9813 - val_loss: 0.0770 - val_accuracy: 0.9758\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.0759 - val_accuracy: 0.9769\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0651 - accuracy: 0.9817 - val_loss: 0.0798 - val_accuracy: 0.9751\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0754 - val_accuracy: 0.9766\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0612 - accuracy: 0.9834 - val_loss: 0.0735 - val_accuracy: 0.9774\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0600 - accuracy: 0.9836 - val_loss: 0.0710 - val_accuracy: 0.9780\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0583 - accuracy: 0.9839 - val_loss: 0.0687 - val_accuracy: 0.9786\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0568 - accuracy: 0.9846 - val_loss: 0.0698 - val_accuracy: 0.9779\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0553 - accuracy: 0.9847 - val_loss: 0.0669 - val_accuracy: 0.9795\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0538 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9789\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0525 - accuracy: 0.9858 - val_loss: 0.0643 - val_accuracy: 0.9789\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0513 - accuracy: 0.9864 - val_loss: 0.0640 - val_accuracy: 0.9798\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0502 - accuracy: 0.9864 - val_loss: 0.0631 - val_accuracy: 0.9801\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0489 - accuracy: 0.9872 - val_loss: 0.0620 - val_accuracy: 0.9796\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0478 - accuracy: 0.9871 - val_loss: 0.0640 - val_accuracy: 0.9791\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0470 - accuracy: 0.9875 - val_loss: 0.0607 - val_accuracy: 0.9804\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0458 - accuracy: 0.9876 - val_loss: 0.0600 - val_accuracy: 0.9804\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0447 - accuracy: 0.9883 - val_loss: 0.0583 - val_accuracy: 0.9813\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.0438 - accuracy: 0.9884 - val_loss: 0.0592 - val_accuracy: 0.9810\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0429 - accuracy: 0.9887 - val_loss: 0.0590 - val_accuracy: 0.9811\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[lr_decay, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "TpfQfqwNEgyb",
    "outputId": "98e21ef8-67c4-45c4-fa0b-b39837e1ae75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation in Test set: \t [loss, accuracy] = [0.058976667242497206, 0.9811]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation in Test set: \\t [loss, accuracy] =\", model.evaluate(x_test, y_test, verbose=0))\n",
    "print(\"Evaluation in Training set:\\t [loss, accuracy] =\",model.evaluate(x_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), \n",
    "                            model.predict(x_test).argmax(axis=1),\n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizzazione Risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "id": "Ttz18SmpEgye",
    "outputId": "4dc420f8-8167-4206-8309-336db470c44b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "ax1 = plt.subplot(121)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.legend(['Training', 'Validation'])\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "ax2.plot(history.history['accuracy'])\n",
    "ax2.plot(history.history['val_accuracy'])\n",
    "ax2.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel plot sopra possiamo vedere che dopo un certo punto il modello migliora molto più il training che il validation set, non può essere completamente considerato un overfitting visto che lo stacco non è così grande (sono diversi solo nella terza cifra decimale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "eLCA6rQRFmFT",
    "outputId": "607c0489-a825-4e82-8dab-35fa799edce5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,5))\n",
    "cf_matrix = confusion_matrix(y_test.argmax(axis=1), model.predict(x_test).argmax(axis=1))\n",
    "ax = sns.heatmap(cf_matrix, cmap='Greens',\n",
    "                 cbar=False, annot=True, fmt='d', linewidths=2, linecolor='gray')\n",
    "ax.tick_params(left=False, bottom=False)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella matrice di confusione possiamo vedere dove sbaglia il modello e possiamo anche trarre delle conclusione da un punto di vista umano ad esempio il modello ha confuso diverse volte il 4 con il 9, e ciò può essere dovuto al fatto che si scrivono un maniera molto simile (avvolte se scritto un po' male confonde anche gli umani), un'altra cifra è il 2 con il 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostriamo con t-SNE la proeizione dell'ultimo layer in uno spazio bi-dimensionale, per fare ciò passeremo attraverso una PCA per ridurre le dimensione da 128 a 20 e poi verrà fatto una t-SNE da 20 dimensioni a 2, ciò è necessario perché t-SNE non si adatta bene a dimensioni grandi di suo.\n",
    "\n",
    "La t-SNE è utile per capire quanto e come ha appreso il modello ad esempio si riescono a vedere i cluster di cifre che si formano, il colore è dovuto al y_test vero, e ciò aiuta anche a capire (come anche nella matrice di confusione) le cifre che il modello potrebbe confondere (non è detto che li confonda solo perché si trovano nello stesso cluster visto che abbiamo ridotto la dimensione)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "tsne_model = Model(model.input, model.layers[-2].output) \n",
    "hidden_features = tsne_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_XHpk97Gn4i"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "pca_result = pca.fit_transform(hidden_features)\n",
    "print('Variance PCA: {}'.format(np.sum(pca.explained_variance_ratio_)))\n",
    "\n",
    "random_index = np.random.randint(0,9999,3333) #3333 elementi a caso ~ 1/3 dei dati\n",
    "#Run T-SNE on the PCA features.\n",
    "tsne = TSNE(n_components=2, verbose = 1)\n",
    "tsne_results = tsne.fit_transform(pca_result[random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pd.DataFrame()\n",
    "color_map = np.argmax(y_test[random_index], axis=1)\n",
    "\n",
    "df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
    "df_subset['tsne-2d-two'] = tsne_results[:,1]\n",
    "df_subset['number'] = color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"number\",\n",
    "    palette=sns.color_palette(\"hls\", 10),\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('t-SNE del Modello')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "E05_Kasela_Pranav_846965.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
